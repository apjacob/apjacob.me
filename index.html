<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Athul Paul Jacob</title>

  <meta name="author" content="Athul Paul Jacob">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Montserrat+Bold" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/favicon.ico">
</head>

<body>

  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr><td style="padding:2.5%;width:40%;max-width:40%"><img style="width:50%;max-width:50%" alt="profile photo" src="images/MIT-logo.svg" class="hoverZoomLink"></td></tr>
    <tr style="padding:0px">

      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <hr>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:40%;max-width:40%"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic_3.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Athul Paul Jacob</name>
              </p>
              <p>I am a Ph.D. student in AI, multi-agent systems and, NLP at <a href="https://www.csail.mit.edu/">MIT CSAIL</a>, advised by <a href="http://web.mit.edu/jda/www/">Jacob Andreas</a>. I am currently also a part-time PhD student researcher at Google Research. I received my master's degree from <a href="https://www.csail.mit.edu/">MIT EECS</a> in 2022, where my thesis was co-advised by <a href="https://www.cs.cmu.edu/~noamb/">Noam Brown</a> and <a href="http://web.mit.edu/jda/www/">Jacob Andreas</a>.
              <p>In 2019, I completed my bachelor's in computer science, combinatorics and optimization at the <a href="https://uwaterloo.ca/">University of Waterloo</a>, where I was advised by <a href="https://vectorinstitute.ai/team/pascal-poupart/">Pascal Poupart</a>. From 2016 until 2018, I was also a visiting student researcher at <a href="https://mila.quebec/">Mila</a> where I worked under the supervision of <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a>.</p>
              <p>I have been fortunate to intern at <a href="https://ai.facebook.com/">Facebook AI Research</a> several times in 2018, 2020 and 2021 as a researcher, where I was mentored by <a href="https://www.cs.cmu.edu/~noamb/">Noam Brown</a>, <a href="http://www.kyunghyuncho.me/">Kyunghyun Cho</a> and <a href="https://ai.facebook.com/people/mike-lewis/">Mike Lewis</a>. I have also previously worked as a research intern at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a> in fall 2017 and winter 2018 with <a href="https://www.microsoft.com/en-us/research/people/alsordon/">Alessandro Sordoni</a> and <a href="https://www.microsoft.com/en-us/research/people/adtrisch/">Adam Trischler</a>. I have also spent time at <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a> and <a href="https://mitibmwatsonailab.mit.edu/">General Catalyst Venture Partners</a> as an AI Fellow</p>

              <p style="text-align:center">
                <a href="mailto:apjacob@mit.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.ca/citations?user=XT3E7RoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/apjacob/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://www.twitter.com/apjacob03"> Twitter </a>
              </p>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <hr>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                Current approaches to solving artificial intelligence falls short of human abilities in their capacity to learn rapidly and flexibly. My current research focuses on utilizing language in a grounded setting to tackle these challenges. My research therefore attempts to combine natural language processing, reinforcement learning and few-shot learning as well as ideas from cognitive psychology.
              </p>
              <p>
                Prior to joining <a href="http://www.mit.edu/">MIT</a>, my focus was primarily on generative modelling (generative adversarial networks, in particular), constituency parsing and neural networks.
              </p>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr><td style="padding:20px;width:75%;vertical-align:middle"><heading>Publications</heading><p>* indicates equal first author contributions</p></td></tr>
         
  		 <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.04030.pdf">
                <papertitle>Modeling Boundedly Rational Agents with Latent Inference Budgets</papertitle>
              </a>
              <br>
              <strong>Athul Paul Jacob</strong>,
              <a>Abhishek Gupta</a>,
              <a>Jacob Andreas</a>
              <br>
              <em>NeurIPS Generalization in Planning Workshop </em>, 2023
              <br>
              <p></p>
              <p> We study the problem of modeling a population of agents pursuing unknown goals subject to unknown computational constraints. We introduce latent inference budget model (L-IBM) that models agents’ computational constraints explicitly, via a latent variable (inferred jointly with a model of agents’ goals) that controls the runtime of an iterative inference algorithm. In three modeling tasks—inferring navigation goals from routes, inferring communicative intents from human utterances, and predicting next moves in human chess games—we show that L-IBMs match or outperform Boltzmann models of decision-making under uncertainty</p>
            </td>
          </tr>

  		 <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://apjacob.me/assets/reco.pdf">
                <papertitle>Regularized Conventions: Equilibrium Computation as a Model of Pragmatic Reasoning</papertitle>
              </a>
              <br>
              <strong>Athul Paul Jacob</strong>,
              <a>Gabriele Farina</a>,
              <a>Jacob Andreas</a>
              <br>
              <em>Arxiv</em>, 2023
              <br>
              <p></p>
              <p> We present a model of pragmatic language understanding called ReCo, where utterances are produced and understood by searching for regularized equilibria of signaling game. Across several datasets capturing real and idealized human judgments about pragmatic implicatures, ReCo matches or improves upon predictions made by best response and rational speech act models of language understanding</p>
            </td>
          </tr>

  		 <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://apjacob.me/assets/consensus.pdf">
                <papertitle>The Consensus Game: Language Model Generation via Equilibrium Search</papertitle>
              </a>
              <br>
              <strong>Athul Paul Jacob</strong>,
              <a>Yikang Shen</a>,
              <a>Gabriele Farina</a>,
              <a>Jacob Andreas</a>
              <br>
              <em>NeurIPS Workshop on robustness of zero/few-shot learning in foundation models (R0-FoMo) </em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p> We introduce a training-free, game-theoretic procedure for language model decoding that improves performance across a number of NLP tasks.</p>
            </td>
          </tr>

  		 <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.science.org/doi/10.1126/science.ade9097">
                <papertitle>Human-Level Play in the Game of Diplomacy by Combining Language Models with Strategic Reasoning</papertitle>
              </a>
              <br>
              <a>FAIR, Anton Bakhtin* , Noam Brown*, Emily Dinan*, Gabriele Farina, Colin Flaherty*, Daniel Fried, Andrew Goff, Jonathan Gray*, Hengyuan Hu*</a>,
              <strong>Athul Paul Jacob*</strong>,
              <a>Mojtaba Komeili, Karthik Konath, Minae Kwon, Adam Lerer*, Mike Lewis*, Alexander H. Miller*, Sasha Mitts, Adithya Renduchintala*, Stephen Roller, Dirk Rowe, Weiyan Shi*, Joe Spisak, Alexander Wei, David Wu*, Hugh Zhang*, Markus Zijlstra</a>,

              <br>
              <em>Science Magazine</em>, November 22, 2022 &nbsp <font color="red"></font>
              <br>

              <p></p>
              <p>We introduce Cicero, an AI agent that demonstrates human-level performance in the mixed-motive 7-player strategic board game Diplomacy that involves natural language negotiation, strategic coordination and persuation. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.05492">
                <papertitle>Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning</papertitle>
              </a>
              <br>
              <a>Anton Bakhtin*</a>,
              <a>David Wu*</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=Ad6O4-0AAAAJ">Adam Lerer*</a>,
              <a>Jonathan Gray*</a>,
              <strong>Athul Paul Jacob*</strong>,
              <a href="https://www.cs.cmu.edu/~gfarina/about/">Gabriele Farina*</a>,
              <a>Alexander H Miller</a>,
              <a href="https://www.cs.cmu.edu/~noamb/">Noam Brown</a>

              <br>
            <em>International Conference on Learning Representations (ICLR)</em>, 2023 &nbsp <font color="red"><strong> (Outstanding Paper Honorable Mention) </strong></font>
              <br>
              <em>NeurIPS Deep Reinforcement Learning Workshop</em>, 2022 &nbsp <font color="red"><strong>(Spotlight Talk)</strong></font>
              <br>

              <p></p>
              <p>We introduce Diplodocus, an AI that achieves expert human-level performance in No-press Diplomacy, a challenging 7-player strategy game that involves both cooperation and competition. </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.12615">
                <papertitle>AutoReply: Detecting Nonsense in Dialogue Introspectively with Discriminative Replies</papertitle>
              </a>
              <br>
              <a>Weiyan Shi</a>,
              <a>Emily Dinan</a>,
              <a>Adi Renduchintala</a>,
              <a>Daniel Fried</a>,
              <strong>Athul Paul Jacob</strong>,
              <a>Zhou Yu</a>,
              <a>Mike Lewis</a>,
              <br>
              <em>Empirical Methods in Natural Language Processing (EMNLP) - Findings</em>, 2023
              <br>

              <p></p>
              <p>A new algorithm for detecting nonsensical responses in complex applications involving dialogues. </p>
            </td>
          </tr>

          <!-- <hr/> -->
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.07544">
                <papertitle>Modeling Strong and Human-Like Gameplay with KL-Regularized Search</papertitle>
              </a>
              <br>
              <strong>Athul Paul Jacob*</strong>,
              <a>David Wu*</a>,
              <a href="https://www.cs.cmu.edu/~gfarina/about/">Gabriele Farina*</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=Ad6O4-0AAAAJ">Adam Lerer</a>,
              <a>Anton Bakhtin</a>,
              <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>,
              <a href="https://www.cs.cmu.edu/~noamb/">Noam Brown</a>

              <br>
              <em>ICLR Workshop on Gamification and Multiagent Solutions</em>, 2022 &nbsp <font color="red"><strong>(Contributed Talk)</strong></font>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2022 &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font>
              <br>
              <p></p>
              <p>We show that by regularizing search towards a human policy, we get state-of-the-art human prediction accuracies in chess, Go and no-press Diplomacy while being significantly stronger. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2104.07219">
                <papertitle>Multitasking Inhibits Semantic Drift</papertitle>
              </a>
              <br>
              <strong>Athul Paul Jacob</strong>,
              <a href="https://ai.facebook.com/people/mike-lewis/">Mike Lewis</a>,
              <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>
              <br>
              <em>North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p>We prove that multitask training eliminates semantic drift in a well-studied family of signaling games, and show that multitask training of neural latent language policies (LLPs) in a complex strategy game reduces drift and while improving sample efficiency. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1806.04168">
                <papertitle>Straight to the Tree: Constituency Parsing with Neural Syntactic Distance</papertitle>
              </a>
              <br>
              <a href="https://mila.quebec/en/person/yikang-shen/">Yikang Shen*</a>,
              <a href="https://hantek.github.io/#">Zhouhan Lin*</a>,
              <strong>Athul Paul Jacob</strong>,
              <a href="https://www.microsoft.com/en-us/research/people/alsordon/">Alessandro Sordoni</a>,
              <a href="https://mila.quebec/en/person/aaron-courville/">Aaron Courville</a>,
              <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a>
              <br>
              <em>Association for Computational Linguistics (ACL)</em>, 2018 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p>A novel constituency parsing scheme free from compounding errors, while being faster and easier to parallelize.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.aclweb.org/anthology/W18-3020/">
                <papertitle>Learning Hierarchical Structures On-The-Fly with a Recurrent-Recursive Model for Sequences</papertitle>
              </a>
              <br>
              <strong>Athul Paul Jacob*</strong>,
              <a href="https://hantek.github.io/#">Zhouhan Lin*</a>,
              <a href="https://www.microsoft.com/en-us/research/people/alsordon/">Alessandro Sordoni</a>,
              <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a>
              <br>
              <em>Association for Computational Linguistics (ACL)</em>, 2018
              <br>
              <p></p>
              <p>A hierarchical model for sequential data that learns a tree on-the-fly. The model adapts its structure and reuses recurrent weights in a recursive manner by creating adaptive skip-connections that ease the learning of long-term dependencies.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1702.08431">
                <papertitle>Boundary-Seeking Generative Adversarial Networks</papertitle>
              </a>
              <br>
              <a href="https://rdevon.github.io/">Devon Hjelm*</a>,
              <strong>Athul Paul Jacob*</strong>,
              <a href="https://scholar.google.com/citations?user=7b5tlJkAAAAJ&hl=en">Tong Che</a>,
              <a href="https://www.microsoft.com/en-us/research/people/adtrisch/">Adam Trischler</a>,
              <a href="http://www.kyunghyuncho.me/">Kyunghyun Cho</a>,
              <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a>
              <br>
              <em> International Conference on Learning Representations (ICLR)</em>, 2018
              <br>
              <p></p>
              <p>A principled method for training generative adversarial networks on discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, providing a policy gradient for training the generator of the network.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Joint Training in Generative Adversarial Networks</papertitle>
              </a>
              <br>
              <a href="https://rdevon.github.io/">Devon Hjelm</a>,
              <strong>Athul Paul Jacob</strong>,
              <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2017
              <br>
              <p></p>
              <p>A generative adversarial network capable of jointly generating images and their labels.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1612.02136">
                <papertitle>Mode Regularized Generative Adversarial Networks</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=7b5tlJkAAAAJ&hl=en">Tong Che*</a>,
              <a href="http://yanran.li/about/">Yanran Li*</a>,
              <strong>Athul Paul Jacob</strong>,
              <a href="https://mila.quebec/en/yoshua-bengio/">Yoshua Bengio</a>,
              <a href="https://www4.comp.polyu.edu.hk/~cswjli/">Wenjie Li</a>
              <br>
              <em> International Conference on Learning Representations (ICLR)</em>, 2017
              <br>
              <p></p>
              <p>We introduce several ways of regularizing the GAN training objective, which can dramatically stabilize the training of these models.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design courtesy of <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
